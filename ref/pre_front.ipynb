{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1847f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시스템 및 파일 조작을 위한 라이브러리\n",
    "import sys\n",
    "import os\n",
    "# 이미지 처리 및 수치 연산을 위한 라이브러리\n",
    "import cv2\n",
    "import numpy as np\n",
    "# HTTP 요청을 위한 라이브러리\n",
    "import requests\n",
    "# GUI 구성을 위한 PyQt6 라이브러리\n",
    "from PyQt6 import uic, QtGui\n",
    "from PyQt6.QtWidgets import QApplication, QMainWindow\n",
    "from PyQt6.QtCore import Qt, QThread, pyqtSignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d421221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI 파일 경로 및 백엔드 서버 URL 설정\n",
    "UI_PATH = \"./ui/mainwindow.ui\"\n",
    "BACKEND_URL = \"http://192.168.0.24:8000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "929868ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoThread(QThread):\n",
    "    \"\"\"\n",
    "    백엔드 서버로부터 MJPEG 스트림을 비동기적으로 수신하는 스레드 클래스입니다.\n",
    "    UI의 멈춤 현상을 방지하기 위해 별도의 스레드에서 네트워크 작업을 수행합니다.\n",
    "    \"\"\"\n",
    "    # 메인 스레드(UI)로 디코딩된 이미지(numpy array)를 전달하기 위한 시그널 정의\n",
    "    change_pixmap_signal = pyqtSignal(np.ndarray)\n",
    "\n",
    "    def __init__(self, url):\n",
    "        super().__init__()\n",
    "        self._run_flag = True\n",
    "        self.url = url\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"스레드 실행 메인 루프: 스트림 연결 및 프레임 파싱\"\"\"\n",
    "        try:\n",
    "            # requests.get에 stream=True를 설정하여 전체 응답을 한 번에 받지 않고 스트리밍으로 받음\n",
    "            # timeout=5는 연결 시도 시 5초간 응답이 없으면 예외를 발생시킴\n",
    "            with requests.get(self.url, stream=True, timeout=5) as r:\n",
    "                r.raise_for_status() # 200 OK가 아닌 경우 예외 발생\n",
    "                \n",
    "                # 수신된 데이터를 임시 저장할 버퍼\n",
    "                byte_buffer = b''\n",
    "                # 서버로부터 10KB 단위로 데이터를 읽어옴\n",
    "                for chunk in r.iter_content(chunk_size=1024*10):\n",
    "                    # 스레드 중지 플래그 확인\n",
    "                    if not self._run_flag:\n",
    "                        break\n",
    "                        \n",
    "                    # 읽어온 청크를 버퍼에 추가\n",
    "                    byte_buffer += chunk\n",
    "                    # JPEG 이미지의 시작(0xffd8)과 끝(0xffd9) 마커를 찾음\n",
    "                    start = byte_buffer.find(b'\\xff\\xd8')\n",
    "                    end = byte_buffer.find(b'\\xff\\xd9')\n",
    "                    \n",
    "                    # 시작과 끝 마커가 모두 존재하면 하나의 온전한 JPEG 프레임이 있는 것임\n",
    "                    if start != -1 and end != -1:\n",
    "                        # 버퍼에서 JPEG 데이터 추출 (끝 마커 2바이트 포함)\n",
    "                        jpg = byte_buffer[start:end+2]\n",
    "                        # 처리한 프레임 이후의 데이터만 버퍼에 남김\n",
    "                        byte_buffer = byte_buffer[end+2:]\n",
    "                        \n",
    "                        try:\n",
    "                            # 바이너리 데이터를 numpy 배열로 변환 후 OpenCV 이미지로 디코딩\n",
    "                            frame = cv2.imdecode(np.frombuffer(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "                            # 디코딩 성공 시 시그널을 통해 UI 스레드로 이미지 전달\n",
    "                            if frame is not None:\n",
    "                                self.change_pixmap_signal.emit(frame)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Frame decode error: {e}\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Could not connect to backend: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "            \n",
    "        print(\"VideoThread finished.\")\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"스레드 종료 요청: 플래그를 False로 설정하고 스레드가 종료될 때까지 대기\"\"\"\n",
    "        self._run_flag = False\n",
    "        self.wait()\n",
    "\n",
    "class ClientWindow(QMainWindow):\n",
    "    \"\"\"메인 애플리케이션 윈도우 클래스\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # .ui 파일이 실제로 존재하는지 확인\n",
    "        if not os.path.exists(UI_PATH):\n",
    "            print(f\"Error: UI file not found at '{UI_PATH}'\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        # .ui 파일을 로드하여 현재 인스턴스(self)에 UI 요소를 연결\n",
    "        uic.loadUi(UI_PATH, self)\n",
    "        self.setWindowTitle(\"Detection Client\")\n",
    "        # 창을 최대화 상태로 표시\n",
    "        self.showMaximized()\n",
    "\n",
    "        # UI에 'log_output'이라는 이름의 위젯이 있다면 로그 메시지 출력\n",
    "        if hasattr(self, \"log_output\"):\n",
    "            # 로그의 최대 줄 수를 100줄로 제한\n",
    "            self.log_output.setMaximumBlockCount(100)\n",
    "            self.log_output.appendPlainText(\"Client started. Connecting to backend...\")\n",
    "\n",
    "        # 비디오 수신을 위한 백그라운드 스레드 생성\n",
    "        self.thread = VideoThread(BACKEND_URL)\n",
    "        # 스레드에서 이미지가 오면 update_image 메서드 호출 연결\n",
    "        self.thread.change_pixmap_signal.connect(self.update_image)\n",
    "        # 스레드 시작\n",
    "        self.thread.start()\n",
    "\n",
    "    def closeEvent(self, event):\n",
    "        # 윈도우가 닫힐 때 호출되는 이벤트 핸들러\n",
    "        print(\"Closing window...\")\n",
    "        # 비디오 스레드를 안전하게 종료\n",
    "        self.thread.stop()\n",
    "        event.accept()\n",
    "\n",
    "    def update_image(self, cv_img):\n",
    "        \"\"\"VideoThread로부터 받은 OpenCV 이미지를 UI의 QLabel에 표시\"\"\"\n",
    "        # OpenCV 형식(BGR)을 Qt 형식(QPixmap)으로 변환\n",
    "        qt_img = self.convert_cv_qt(cv_img)\n",
    "        \n",
    "        # UI에 'video_display' 라벨이 있는 경우 이미지 설정\n",
    "        if hasattr(self, \"video_display\"):\n",
    "            # 라벨의 현재 크기에 맞춰 이미지를 스케일링 (비율 유지, 부드러운 변환)\n",
    "            pixmap = qt_img.scaled(\n",
    "                self.video_display.size(),\n",
    "                Qt.AspectRatioMode.KeepAspectRatio,\n",
    "                Qt.TransformationMode.SmoothTransformation\n",
    "            )\n",
    "            self.video_display.setPixmap(pixmap)\n",
    "\n",
    "    def convert_cv_qt(self, cv_img):\n",
    "        \"\"\"OpenCV 이미지(numpy array)를 PyQt의 QPixmap으로 변환하는 헬퍼 메서드\"\"\"\n",
    "        # OpenCV는 BGR 순서를 사용하므로 RGB 순서로 변환\n",
    "        rgb_image = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\n",
    "        # 이미지의 높이, 너비, 채널 수 가져오기\n",
    "        h, w, ch = rgb_image.shape\n",
    "        # 한 줄의 바이트 수 계산 (너비 * 채널 수)\n",
    "        bytes_per_line = ch * w\n",
    "        # QImage 객체 생성 (데이터, 너비, 높이, 라인당 바이트 수, 포맷)\n",
    "        convert_to_Qt_format = QtGui.QImage(\n",
    "            rgb_image.data, w, h, bytes_per_line, QtGui.QImage.Format.Format_RGB888\n",
    "        )\n",
    "        # QImage를 QPixmap으로 변환하여 반환\n",
    "        return QtGui.QPixmap.fromImage(convert_to_Qt_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b26646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QApplication 인스턴스 생성 (커맨드 라인 인수 전달)\n",
    "app = QApplication(sys.argv)\n",
    " # 메인 윈도우 생성 및 표시\n",
    "window = ClientWindow()\n",
    "window.show()\n",
    "# 이벤트 루프 시작 및 종료 코드 반환\n",
    "sys.exit(app.exec())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
